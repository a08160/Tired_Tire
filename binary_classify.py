# not-tire / tire ì— ëŒ€í•œ ì´ì§„ ë¶„ë¥˜
# MobileNetV2 í™œìš© (ì•± ê°œë°œì„ ê³ ë ¤)
# Image Size: 224x224
# íƒ€ì´ì–´ ê°ì²´ê°€ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” ì§€ì— ëŒ€í•œ ì—¬ë¶€ë¥¼ íŒë‹¨

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# âœ… 1. í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 32
EPOCHS = 5
LR = 0.001
DATA_DIR = './classify_dataset'

# âœ… 2. ë°ì´í„° ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
])

train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=transform)
test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# âœ… 3. ëª¨ë¸ ë¡œë”© (MobileNetV2)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = models.mobilenet_v2(pretrained=True)
model.classifier[1] = nn.Linear(model.last_channel, 2)  # Binary classification
model = model.to(device)

# âœ… 4. Loss & Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LR)

# âœ… 5. í•™ìŠµ ë£¨í”„ + ì§„í–‰ë¥  + ìµœì  ëª¨ë¸ ì €ì¥
train_losses = []
test_accuracies = []
best_acc = 0.0  # ìµœì  ì„±ëŠ¥ ì¶”ì ìš©

for epoch in range(EPOCHS):
    model.train()
    running_loss = 0.0
    total_batches = len(train_loader)
    print(f"\nEpoch [{epoch+1}/{EPOCHS}]")

    for batch_idx, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

        # âœ… ì§„í–‰ í¼ì„¼íŠ¸ ì¶œë ¥
        progress = (batch_idx + 1) / total_batches * 100
        print(f"\rProgress: {progress:.2f}%", end='')

    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    # âœ… 6. í‰ê°€
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    acc = correct / total
    test_accuracies.append(acc)

    print(f"\nEpoch Result => Loss: {train_loss:.4f} | Test Acc: {acc:.4f}")

    # âœ… ìµœì  ëª¨ë¸ ì €ì¥
    if acc > best_acc:
        best_acc = acc
        os.makedirs('model_weights', exist_ok=True)
        torch.save(model.state_dict(), 'model_weights/best_tire_classifier.pth')
        print(f"ğŸ“Œ Best model saved at Epoch {epoch+1} with Accuracy: {acc:.4f}")

# âœ… 7. ê²°ê³¼ ì‹œê°í™”
plt.plot(train_losses, label='Train Loss')
plt.plot(test_accuracies, label='Test Accuracy')
plt.legend()
plt.title("Training Progress")
plt.show()

print(f"ğŸ‰ Training complete. Best Test Accuracy: {best_acc:.4f}")
